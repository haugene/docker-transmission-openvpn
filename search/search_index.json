{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"OpenVPN and Transmission with WebUI  <p>   Docker container running Transmission torrent client with WebUI over an OpenVPN tunnel    </p>"},{"location":"#welcome_to_the_documentation","title":"Welcome to the documentation!","text":"<p>Writing good documentation is hard but we think that we're getting closer to a good place to search for answers. These pages are not done yet and you will meet some \"under construction\" notices. Please bear with us and if you spot mistakes or have suggestions - submit a PR :)</p>"},{"location":"#general_information","title":"General Information","text":"<ul> <li>The basic building blocks</li> <li>Running the container</li> <li>VPN and networking in containers</li> <li>Supported providers and server locations</li> <li>Provider specific features/instructions</li> <li>Configuration options list</li> </ul>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Frequently asked questions</li> <li>Debugging your setup</li> <li>Tips &amp; Tricks</li> </ul>"},{"location":"#additional_features","title":"Additional features","text":"<ul> <li>Web proxy: Privoxy</li> <li>RSS Plugin support</li> </ul>"},{"location":"building-blocks/","title":"The basic building blocks","text":""},{"location":"building-blocks/#the_goal","title":"The goal","text":"<p>The core functionality of this image is to let the user run a VPN tunnel and Transmission as easy as possible. Transmission should only run while the VPN is active, and any disconnect from VPN should cause Transmission to stop.</p> <p>The container should provide community best practices on how to configure the kill switch, firewall and tweaks on the OpenVPN configs to make it run as fast and secure as possible.</p>"},{"location":"building-blocks/#it_goes_like_this","title":"It goes like this","text":"<p>To understand how it works, these are the most important events and who/what starts them.</p> <ol> <li>You start the container</li> <li>The container starts OpenVPN</li> <li>OpenVPN starts/stops Transmission</li> </ol> <p>When you start the container it is instructed to run a script to start OpenVPN. This is defined in the Dockerfile. This script is responsible for doing initial setup and preparing what is needed for OpenVPN to run successfully.</p>"},{"location":"building-blocks/#starting_openvpn","title":"Starting OpenVPN","text":"<p>The main purpose of the start-up script is to figure out which OpenVPN config to use. OpenVPN itself can be started with a single argument, and that is the config file. We also add a few more to tell it to start Transmission when the VPN tunnel is started and to stop Transmission when OpenVPN is stopped. That's it.</p> <p>Apart from that, the script does some firewall config, VPN interface setup and possibly other things based on your settings. There are also some reserved script names that a user can mount/add to the container to include their own scripts as a part of the setup or teardown of the container.</p> <p>Anyways! You have probably seen the docker run and docker-compose configuration examples and you've put two and two together: This is where environment variables come in. Setting environment variables is a common way to pass configuration options to containers and it is the way we have chosen to do it here. So far, we've explained the need for <code>OPENVPN_PROVIDER</code> and <code>OPENVPN_CONFIG</code>. We use the combination of these two to find the right config. <code>OPENVPN_CONFIG</code> is not set as a mandatory option as each provider should have a default config that will be used if none is set.</p> <p>With the config file identified we're ready to start OpenVPN, the only thing missing are probably a username and password. There are some free providers out there, but they are the exceptions to the rule. We must inject the username/password into the config somehow. Again there are exceptions but the majority of configs from regular providers contain a line with <code>auth-user-pass</code> which will make OpenVPN prompt for username and password when you start a connection. That will obviously not work for us, so we need to modify that option. If it's followed by a path to a file, it will read the first line of that file as username and the second line as password.</p> <p>You provide your username and password as <code>OPENVPN_USERNAME</code> and <code>OPENVPN_PASSWORD</code>. These will be written into two lines in a file called <code>/config/openvpn-credentials.txt</code> on start-up by the start script. Having written your username/password to a file, we can successfully start OpenVPN.</p>"},{"location":"building-blocks/#starting_transmission","title":"Starting Transmission","text":"<p>We're using the <code>up</code> option from OpenVPN to start Transmission.</p> <p>--up cmd \u00a0\u00a0\u00a0\u00a0Run command cmd after successful TUN/TAP device open</p> <p>This means that Transmission will be started when OpenVPN has connected successfully and opened the tunnel device. We are having OpenVPN call the tunnelUp.sh script which in turn will call the start scripts for Transmission and  Privoxy.</p> <p>The up script will be called with a number of parameters from OpenVPN, and among them is the IP of the tunnel interface. This IP is the one we've been assigned by DHCP from the OpenVPN server we're connecting to. We use this value to override Transmission\u2019s bind address, so we'll only listen for traffic from peers on the VPN interface.</p> <p>The start-up script checks to see if one of the alternative web UIs should be used for Transmission. It also sets up the user that Transmission should be run as, based on the PUID and PGID passed by the user along with selecting preferred logging output and a few other tweaks.</p> <p>Before starting Transmission we also need to see if any settings should be overridden. One example of this is binding Transmission to the IP we've gotten from our VPN provider. Here we check if we find any environment variables that match a setting that we also see in settings.json. This is described in the config section. Setting a matching environment variable will then override the setting in Transmission.</p> <p>OpenVPN does not pass the environment variables it was started with to Transmission. To still be able to access them when starting Transmission, we're writing the ones we need to a file when starting OpenVPN. That way we can read them back and use them here. With the environment variables in place this script then overwrites the selected properties in settings.json and we're ready to start Transmission itself.</p> <p>After starting Transmission there is an optional step that some providers have; to get an open port and set it in Transmission. Opening a port in your local router does not work. I made that bold because it's a recurring theme. It's not intuitive until it is, I guess. Since all your traffic is going through the VPN, which is kind of the point, the port you have to open is not on your router. Your router's external IP address is the destination of those packets. It is on your VPN provider\u2019s end that it has to be opened. Some providers support this, others don't. We try to write scripts for those that do, and that script will be executed after starting Transmission if it exists for your provider.</p> <p>At this point, Transmission is running, and everything is great! But you might not be able to access it, and that's the topic of the networking section.</p>"},{"location":"config-options/","title":"Configuration options","text":""},{"location":"config-options/#required_environment_options","title":"Required environment options","text":"Variable Function Example <code>OPENVPN_PROVIDER</code> Sets the OpenVPN provider to use. <code>OPENVPN_PROVIDER=provider</code>. Supported providers and their config values are listed in the table above. <code>OPENVPN_USERNAME</code> Your OpenVPN username <code>OPENVPN_USERNAME=asdf</code> <code>OPENVPN_PASSWORD</code> Your OpenVPN password, beware of special characters. Docker run vs docker-compose (using YAML) interpret special characters differently, see  Yaml special characters <code>OPENVPN_PASSWORD=asdf</code> <p>Docker secrets are available to define OPENVPN_USER and OPENVPN_PASSWORD.</p> <ul> <li>remove OPENVPN_USERNAME, OPENVPN_PASSWORD from environment.</li> <li>write your credentials in one file: openvpn_creds</li> <li>add to your compose YAML:</li> </ul> <pre><code>version: '3.8'\nservices:\n transmission:\n    ....\n    secrets:\n        - openvpn_creds\n\nsecrets:\n    openvpn_creds:\n        file: ./openvpn_creds\n</code></pre>"},{"location":"config-options/#network_configuration_options","title":"Network configuration options","text":"Variable Function Example <code>OPENVPN_CONFIG</code> Sets the OpenVPN endpoint to connect to. <code>OPENVPN_CONFIG=UK Southampton</code> <code>OPENVPN_OPTS</code> Will be passed to OpenVPN on startup See OpenVPN doc <code>LOCAL_NETWORK</code> Sets the local network that should have access. Accepts comma-separated list. <code>LOCAL_NETWORK=192.168.0.0/24</code> <code>CREATE_TUN_DEVICE</code> Creates /dev/net/tun device inside the container, mitigates the need to mount the device from the host <code>CREATE_TUN_DEVICE=true</code> <code>PEER_DNS</code> Controls whether to use the DNS provided by the OpenVPN endpoint. To use your host DNS rather than what is provided by OpenVPN, set <code>PEER_DNS=false</code>.  This allows for potential DNS leakage. <code>PEER_DNS_PIN_ROUTES</code> Controls whether to force traffic to peer DNS through the OpenVPN tunnel. To disable this default, set <code>PEER_DNS_PIN_ROUTES=false</code>."},{"location":"config-options/#timezone_option","title":"Timezone option","text":"<p>Set a custom timezone in tz database format. Look here for a list of valid timezones. Defaults to UTC.</p> Variable Function Example <code>TZ</code> Set Timezone <code>TZ=UTC</code>"},{"location":"config-options/#firewall_configuration_options","title":"Firewall configuration options","text":"<p>When enabled, the firewall blocks everything except traffic to the peer port and traffic to the rpc port from the LOCAL_NETWORK and the internal docker gateway.</p> <p>If TRANSMISSION_PEER_PORT_RANDOM_ON_START is enabled then it allows traffic to the range of peer ports defined by TRANSMISSION_PEER_PORT_RANDOM_HIGH and TRANSMISSION_PEER_PORT_RANDOM_LOW.</p> Variable Function Example <code>ENABLE_UFW</code> Enables the firewall <code>ENABLE_UFW=true</code> <code>UFW_ALLOW_GW_NET</code> Allows the gateway network through the firewall. Off defaults to only allowing the gateway. <code>UFW_ALLOW_GW_NET=true</code> <code>UFW_EXTRA_PORTS</code> Allows the comma-separated list of ports through the firewall. Respects UFW_ALLOW_GW_NET. <code>UFW_EXTRA_PORTS=9910,23561,443</code> <code>UFW_DISABLE_IPTABLES_REJECT</code> Prevents the use of <code>REJECT</code> in the <code>iptables</code> rules, for hosts without the <code>ipt_REJECT</code> module (such as the Synology NAS). <code>UFW_DISABLE_IPTABLES_REJECT=true</code>"},{"location":"config-options/#health_check_option","title":"Health check option","text":"<p>Because your VPN connection can sometimes fail, Docker will run a health check on this container every 5 minutes to see if the container is still connected to the internet. By default, this check is done by pinging google.com once. You change the host that is pinged.</p> Variable Function Example <code>HEALTH_CHECK_HOST</code> this host is pinged to check if the network connection still works <code>google.com</code>"},{"location":"config-options/#permission_configuration_options","title":"Permission configuration options","text":"<p>By default, the startup script applies a default set of permissions and ownership on the transmission download, watch and incomplete directories. The GLOBAL_APPLY_PERMISSIONS directive can be used to disable this functionality.</p> Variable Function Example <code>GLOBAL_APPLY_PERMISSIONS</code> Disable setting of default permissions <code>GLOBAL_APPLY_PERMISSIONS=false</code>"},{"location":"config-options/#alternative_web_uis","title":"Alternative Web UIs","text":"<p>This container comes bundled with some alternative Web UIs:</p> <ul> <li>Combustion UI</li> <li>Kettu</li> <li>Transmission-Web-Control</li> <li>Flood for Transmission</li> <li>Shift</li> <li>Transmissionic</li> </ul> <p>To use one of them instead of the default Transmission UI you can set <code>TRANSMISSION_WEB_UI</code> to either <code>combustion</code>, <code>kettu</code>, <code>transmission-web-control</code>, <code>flood-for-transmission</code>, <code>shift</code> or <code>transmissionic</code> respectively.</p> Variable Function Example <code>TRANSMISSION_WEB_UI</code> Use the specified bundled web UI <code>TRANSMISSION_WEB_UI=combustion</code> <code>TRANSMISSION_WEB_UI=kettu</code> <code>TRANSMISSION_WEB_UI=transmission-web-control</code> <code>TRANSMISSION_WEB_UI=flood-for-transmission</code> <code>TRANSMISSION_WEB_UI=shift</code> <code>TRANSMISSION_WEB_UI=transmissionic</code>"},{"location":"config-options/#user_configuration_options","title":"User configuration options","text":"<p>By default, everything will run as the root user. However, it is possible to change who runs the transmission process. You may set the following parameters to customize the user id that runs Transmission.</p> Variable Function Example <code>PUID</code> Sets the user id who will run transmission <code>PUID=1003</code> <code>PGID</code> Sets the group id for the transmission user <code>PGID=1003</code>"},{"location":"config-options/#transmission_configuration_options","title":"Transmission configuration options","text":"<p>In previous versions of this container the settings were not persistent but were generated from environment variables on container startup. This had the benefit of being very explicit and reproducible but you had to provide Transmission config as environment variables if you wanted them to stay that way between container restarts. This felt cumbersome to many.</p> <p>As of version 4.2, this is no longer true. Settings are now persisted in the <code>/config/transmission-home</code> folder in the container and as long as you mount <code>/config</code> you should be able to configure Transmission using the UI as you normally would. If you are using the container from earlier versions and have not changed the location of transmission-home to /config, you will see a warning message that the default has changed. You can manually move the folder to your /config volume directory after stopping the container and adding the /config mount to your container setup (compose/run etc).</p> <p>You may still override Transmission options by setting environment variables if that's your thing. The variables are named after the transmission config they target but are prefixed with <code>TRANSMISSION_</code>, capitalized, and <code>-</code> is converted to <code>_</code>.</p> <p>For example:</p> Transmission variable name Environment variable name <code>speed-limit-up</code> <code>TRANSMISSION_SPEED_LIMIT_UP</code> <code>speed-limit-up-enabled</code> <code>TRANSMISSION_SPEED_LIMIT_UP_ENABLED</code> <code>ratio-limit</code> <code>TRANSMISSION_RATIO_LIMIT</code> <code>ratio-limit-enabled</code> <code>TRANSMISSION_RATIO_LIMIT_ENABLED</code> <p>A full list of variables can be found in the Transmission documentation here.</p> <p>All variables overridden by environment variables will be logged during startup.</p> <p>PS: <code>TRANSMISSION_BIND_ADDRESS_IPV4</code> will automatically be overridden to the IP assigned to your OpenVPN tunnel interface. This ensures that Transmission only listens for torrent traffic on the VPN interface and is part of the fail-safe mechanisms.</p>"},{"location":"config-options/#dropping_default_route_from_iptables_advanced","title":"Dropping default route from iptables (advanced)","text":"<p>Some VPNs do not override the default route, but rather set other routes with a lower metric. This might lead to the default route (your untunneled connection) being used.</p> <p>To drop the default route set the environment variable <code>DROP_DEFAULT_ROUTE</code> to <code>true</code>.</p> <p>Note: This is not compatible with all VPNs. You can check your iptables routing with the <code>ip r</code> command in a running container.</p>"},{"location":"config-options/#changing_logging_locations","title":"Changing logging locations","text":"<p>By default, Transmission will log to a file in <code>TRANSMISSION_HOME/transmission.log</code>.</p> <p>To log to stdout instead set the environment variable <code>LOG_TO_STDOUT</code> to <code>true</code>.</p> <p>Note: By default, stdout is what container engines read logs from. Set this to true to have Transmission logs in commands like <code>docker logs</code> and <code>kubectl logs</code>. OpenVPN currently only logs to stdout.</p>"},{"location":"config-options/#custom_scripts","title":"Custom scripts","text":"<p>If you ever need to run custom code before or after Transmission is executed or stopped, you can use the custom scripts feature. Custom scripts are located in the <code>/scripts</code> directory which is empty by default. To enable this feature, you'll need to mount the <code>/scripts</code> directory.</p> <p>Once <code>/scripts</code> is mounted you'll need to write your custom code in the following bash shell scripts:</p> Script Function /scripts/openvpn-pre-start.sh This shell script will be executed before OpenVPN starts /scripts/openvpn-post-config.sh This shell script will be executed after OpenVPN config /scripts/transmission-pre-start.sh This shell script will be executed before transmission starts /scripts/transmission-post-start.sh This shell script will be executed after transmission starts /scripts/routes-post-start.sh This shell script will be executed after routes are added /scripts/transmission-pre-stop.sh This shell script will be executed before transmission stops /scripts/transmission-post-stop.sh This shell script will be executed after transmission stops <p>Don't forget to include the <code>#!/bin/bash</code> shebang and to make the scripts executable using <code>chmod a+x</code></p>"},{"location":"config-options/#debugging","title":"Debugging","text":"<p>By default, commands are not echoed to stdout before being processed. Setting DEBUG to any value other than the string false will trigger command echo (set -x) for all bash scripts.</p> Variable Function Example DEBUG Echo all commands to stdout. DEBUG=true"},{"location":"debug/","title":"Debugging your setup","text":"<p>The goal of this page is to provide a common set of tests that can be run to try to narrow down an issue with the container before you create a new issue for it. We see a lot of repeat business in the issues section and spending time answering questions for individual setups takes away from improving the container and making it more stable in the first place.</p> <p>This guide should be improved over time but can hopefully help you point out the most common errors and provide some pointers on how to proceed. A summary of what you've tried should be added to the description if you can't figure out what's wrong with your setup and create an issue for it.</p>"},{"location":"debug/#introduction_and_assumptions","title":"Introduction and assumptions","text":"<p>I am going to assume that you have shell access to the host and that you can use <code>docker run</code> commands to test it. If you're a docker-compose user then you can make a similar setup in docker-compose. If you are using any of the NAS container orchestration UIs then you just have to mimic this behaviour as best you can. Note that you can ssh into the NAS and run commands directly.</p> <p>NOTE: The commands listed here use the --rm flag which will remove the container from the host when it shuts down. And as we're not mounting any volumes here, your host system will not be altered from running any of these commands. If any command breaks with this principle it will be noted.</p>"},{"location":"debug/#checking_that_docker_works_properly","title":"Checking that Docker works properly","text":"<p>For this container to work, you have to have a working Docker installation on your host.</p> <p>We'll begin very simply with this command that will print a welcome message if Docker is properly installed.</p> <pre><code>docker run --rm hello-world\n</code></pre> <p>Then we can try to run an alpine image, install curl and run curl to get your public IP. This verifies that Docker containers on your host have working internet access and that they can look up hostnames with DNS.</p> <pre><code>docker run --rm -it alpine sh -c \"apk add curl &amp;&amp; curl ipecho.net/plain\"\n</code></pre> <p>If you get an error with \"Could not resolve host\" then you have to look at the DNS options in the Docker run reference.</p> <p>Finally, we will check that your Docker daemon runs with a bridge network as the default network driver. The following command runs an alpine container and prints its iptable routes. It probably outputs two lines and one of them starts with <code>172.x.0.0/16 dev eth0</code> and the other one also references <code>172.x.0.1</code>. The 172 addresses are a sign that you're on a Docker bridge network. If your local IP like <code>192.168.x.y</code> shows up your container is running with host networking and the VPN container would affect the entire host instead of just affecting Transmission running within the container.</p> <pre><code>docker run --rm -it alpine ip r\n</code></pre> <p>If you have gotten any errors so far you have to refer to Docker documentation and other forums to get help getting Docker to work.</p>"},{"location":"debug/#try_running_the_container_with_an_invalid_setup","title":"Try running the container with an invalid setup","text":"<p>We'll keep this brief because it's not the most useful step, but you can verify a bit anyways.</p> <p>Run this command (even if PIA is not your provider) and do not insert your real username/password:</p> <pre><code>docker run --rm -it -e OPENVPN_PROVIDER=PIA -e OPENVPN_CONFIG=france -e OPENVPN_USERNAME=donald -e OPENVPN_PASSWORD=duck haugene/transmission-openvpn\n</code></pre> <p>At this point, the commands are getting longer. I'll start breaking them up into lines using \\ to escape the line breaks. For those that are new to shell commands; a \\ at the end of the line will tell the shell to keep on reading as if it was on the same line. You can copy-paste this somewhere and put everything on the same line and remove the \\ characters if you want to. The same command then becomes:</p> <pre><code>docker run --rm -it \\\n  -e OPENVPN_PROVIDER=PIA \\\n  -e OPENVPN_CONFIG=france \\\n  -e OPENVPN_USERNAME=donald \\\n  -e OPENVPN_PASSWORD=duck \\\n  haugene/transmission-openvpn\n</code></pre> <p>This command should fail and exit with three lines that look like this (I've trimmed it a bit):</p> <pre><code>Peer Connection Initiated with ...\nAUTH: Received control message: AUTH_FAILED\nSIGTERM[soft,auth-failure] received, process exiting\n</code></pre> <p>And this is not nothing. The container has made contact with the VPN server and they have agreed that you have not provided correct authentication. So we're getting somewhere.</p>"},{"location":"debug/#running_with_a_valid_configuration","title":"Running with a valid configuration","text":"<p>Upgrading slightly from the last command we need to add our real provider, config and username/password. This is what the container needs to be able to connect to VPN. The config is not a mandatory option and all providers should have a default that is used if you don't set it. But I will set it here anyways as I think it's good to know where and what you're connecting to.</p> <p>The command is basically the same. I'm going to stick with PIA/France as I am a PIA user, but you should set one of the supported providers or provide your own config using the  custom configuration option. Since I'm now expecting to connect successfully to my VPN provider, I have to give the container elevated access to modify networking needed to establish a VPN tunnel. I'll add the <code>--cap-add=NET_ADMIN</code> and you can read more about that here.</p> <p>Also because I'm using PIA and they support port forwarding which is automatically configured in this  container, I will disable that script for now. It's unnecessary at this point and I don't want to introduce more error sources than I have to.</p> <pre><code>docker run --rm -it --cap-add=NET_ADMIN \\\n  -e OPENVPN_PROVIDER=PIA \\\n  -e OPENVPN_CONFIG=france \\\n  -e OPENVPN_USERNAME=username \\\n  -e OPENVPN_PASSWORD=password \\\n  -e DISABLE_PORT_UPDATER=true \\\n  haugene/transmission-openvpn\n</code></pre> <p>The logs should be longer this time, and you should end up with <code>Initialization Sequence Completed</code> at the end. If you don't see this message then look through your logs for errors and see if you can find your error in the list in the FAQ. If the error is not easily understandable or listed in the FAQ, open a new issue on it.</p>"},{"location":"debug/#checking_if_transmission_is_running","title":"Checking if Transmission is running","text":"<p>We're continuing with the <code>docker run</code> command from the last example. Because we have not yet introduced the LOCAL_NETWORK variable you cannot access Transmission that is running in the container. We have not exposed any ports on your host either so Transmission is not reachable from outside of the container as of now.</p> <p>You don't need to expose Transmission outside of the container to contact it though. You can get another shell inside the same container that you are running and try to curl Transmission web UI from there.</p> <p>If this gets too complicated then you can skip to the next point, but please try to come back here if the next point fails. One thing is not being able to access Transmission which might be network related, but if Transmission is not running it's something else entirely.</p> <p>If you run <code>docker ps</code> you should get a list of all running docker containers. If the list is too long then you can ask for only transmission-openvpn containers with <code>docker ps --filter ancestor=haugene/transmission-openvpn</code>.</p> <p>Using the Container ID from that list you can run <code>docker exec -it &lt;container-id&gt; bash</code>. Once you're in the container run <code>curl localhost:9091</code> and you should expect to get <code>&lt;h1&gt;301: Moved Permanently&lt;/h1&gt;</code> in return. This is because Transmission runs at /web/transmission and tries to redirect you there. It doesn't matter because you now see that Transmission is running and apparently doing well.</p>"},{"location":"debug/#accessing_transmission_web_ui","title":"Accessing Transmission Web UI","text":"<p>If you've come this far we hopefully will be able to connect to the Transmission Web UI from your browser. To do this we have to know what LAN IP your system is on. The reason for this is a bit complex and is described in the VPN networking section. The short version is that OpenVPN needs to be able to differentiate between what traffic to tunnel and what to let go. Since the VPN is running on the Docker bridge network it is not able to detect computers on your LAN as actually being local devices.</p> <p>We'll base ourselves on the command from the previous sections, but to access Transmission, we need to expose the 9091 port to the host and tell the containers what IP ranges NOT to tunnel. Whatever you put in LOCAL_NETWORK will be trusted as a local network and traffic to those IPs will not be tunnelled. Here we will assume that you're on one of the common 192.168.x.y subnets.</p> <p>The command then becomes:</p> <pre><code>docker run --rm -it --cap-add=NET_ADMIN \\\n  -p 9091:9091 \\\n  -e LOCAL_NETWORK=192.168.0.0/16 \\\n  -e OPENVPN_PROVIDER=PIA \\\n  -e OPENVPN_CONFIG=france \\\n  -e OPENVPN_USERNAME=username \\\n  -e OPENVPN_PASSWORD=password \\\n  -e DISABLE_PORT_UPDATER=true \\\n  haugene/transmission-openvpn\n</code></pre> <p>With any luck, you should now be able to access Transmission at http://localhost:9091 or whatever server IP where you have started the container.</p> <p>NOTE: If you're trying to run this alongside another container you can use <code>-p 9092:9091</code> to bind 9092 on the host instead of 9091 and avoid port conflict.</p>"},{"location":"debug/#now_what","title":"Now what?","text":"<p>If this guide has failed at some point then you should create an issue for it. Please add the command that you ran and the logs that were produced.</p> <p>If you're now able to access Transmission and it seems to work correctly then you should add a volume mount to the <code>/data</code> folder in the container. You'll then have a setup like what's shown on the main GitHub page of this project.</p> <p>If you have another setup that does not work then you now have two versions to compare and maybe that will lead you to find the error in your old setup. If the setup is the same but this version works then the error is in your state. Transmission stores its state in /data/transmission-home by default and it might have gotten corrupt. One simple thing to try is to delete the settings.json file that is found here. We do mess with that file and we might have corrupted it. Apart from that, we do not change anything within the Transmission folder and any issues should be asked in Transmission forums.</p>"},{"location":"debug/#conclusion","title":"Conclusion","text":"<p>I hope this has helped you to solve your problem or at least narrow down where it's coming from. If you have suggestions for improvements do not hesitate to create an issue or even better open a PR with your proposed changes.</p>"},{"location":"faq/","title":"Frequently asked questions","text":"<ul> <li>The container runs, but I can't access the web ui</li> <li>How do I enable authentication in the web ui</li> <li>How do I verify that my traffic is using VPN</li> <li>RTNETLINK answers: File exists</li> <li>RTNETLINK answers: Invalid argument</li> <li>TUNSETIFF tun: Operation not permitted</li> <li>Error resolving host address</li> <li>Container loses connection after some time</li> <li>Set the ping-exit option for OpenVPN and restart-flag in Docker</li> <li>Use a third-party tool to monitor and restart the container</li> <li>Send Username Password via file</li> <li>AUTH: Received control message: AUTH_FAILED</li> </ul>"},{"location":"faq/#the_container_runs_but_i_cant_access_the_web_ui","title":"The container runs, but I can't access the web UI","text":"<p>TODO: Short explanation and link to networking</p>"},{"location":"faq/#how_do_i_enable_authentication_in_the_web_ui","title":"How do I enable authentication in the web UI","text":"<p>You can do this either by setting the appropriate fields in <code>settings.json</code> which is found in TRANSMISSION_HOME which defaults to <code>/config/transmission-home</code> so it will be available on your host where you mount the <code>/config</code> volume. Remember that Transmission overwrites the config when it shuts down, so do this when the container is not running.</p> <p>Or you can set it using the convenience environment variables. They will then override the settings on every container startup. The environment variables you have to set are:</p> <ul> <li><code>TRANSMISSION_RPC_USERNAME=username</code></li> <li><code>TRANSMISSION_RPC_PASSWORD=password</code></li> <li><code>TRANSMISSION_RPC_AUTHENTICATION_REQUIRED=true</code></li> </ul> <p>PS: Be cautious of special characters in the username or password. We've had multiple errors with that and have not provided a fix yet. Escaping special characters could be an option, but the easiest solution is just to avoid them. Make the password longer instead ;) Or write it into <code>settings.json</code> manually as first described. Also, look up differences between how yaml special characters are escaped vs in docker run</p> <p>Docker secrets are also supported for the rpc credentials. To use a secret, remove both the <code>TRANSMISSION_RPC_USERNAME</code> and <code>TRANSMISSION_RPC_PASSWORD</code> environment variables and add a secret named <code>rpc_creds</code>. The secret file must contain two lines, the first line is the username and the second line is the password. Then just add it as a secret to docker, and it will be picked up automatically. This is why the name of the secret is important.</p>"},{"location":"faq/#how_do_i_verify_that_my_traffic_is_using_vpn","title":"How do I verify that my traffic is using VPN","text":"<p>There are many ways of doing this, and I welcome you to add to this list if you have any suggestions.</p> <p>You can exec into the container and through the shell use <code>curl</code> to ask for your public IP. There are multiple endpoints for this but here are a few suggestions:</p> <ul> <li><code>curl http://ipinfo.io/ip</code></li> <li><code>curl http://ipecho.net/plain</code></li> <li><code>curl icanhazip.com</code></li> </ul> <p>Example command: <code>docker exec &lt;container-name&gt; curl --silent \"http://ipinfo.io/ip\"</code></p> <p>Or you could use a test torrent service to download a torrent file and then you can get the IP from that tracker.</p> <ul> <li>https://github.com/cbdevnet/ipmagnet/</li> <li>https://torguard.net/checkmytorrentipaddress.php</li> </ul>"},{"location":"faq/#rtnetlink_answers_file_exists","title":"RTNETLINK answers: File exists","text":"<p>TODO: Conflicting LOCAL_NETWORK values. Short explanation and link to networking</p>"},{"location":"faq/#rtnetlink_answers_invalid_argument","title":"RTNETLINK answers: Invalid argument","text":"<p>This can occur because you have specified an invalid subnet or possibly specified an IP Address in CIDR format instead of a subnet. Your LOCAL_NETWORK property must be aimed at a subnet and not at an IP Address. </p> <p>A valid example would be</p> <pre><code> ```\n LOCAL_NETWORK=10.80.0.0/24\n ```\n</code></pre> <p>but an invalid target route that would cause this error might be </p> <pre><code> ```\n #Invalid because the subnet for this range would be 10.20.30.0/24\n LOCAL_NETWORK=10.20.30.45/24\n ```\n</code></pre> <p>To check your value, you can use a subnet calculator.  * Enter your IP Address - the portion before the mask, <code>10.20.30.45</code> here * Select the subnet that matches - the <code>/24</code> portion here * Take the Network Address that is returned - <code>10.20.30.0</code> in this case </p>"},{"location":"faq/#tunsetiff_tun_operation_not_permitted","title":"TUNSETIFF tun: Operation not permitted","text":"<p>This is usually a question of permissions. Have you set the NET_ADMIN capabilities to the container? What if you use <code>docker run --privileged</code>, do you still get that error?</p> <p>This is an error where we haven't got too much information. If the hints above get you nowhere, create an issue.</p>"},{"location":"faq/#error_resolving_host_address","title":"Error resolving host address","text":"<p>This error can happen at multiple places in the scripts. The most common is that it happens with <code>curl</code> trying to download the latest .ovpn config bundle for those providers that have an update script, or that OpenVPN throws the error when trying to connect to the VPN server.</p> <p>The curl error looks something like <code>curl: (6) Could not resolve host: ...</code> and OpenVPN says <code>RESOLVE: Cannot resolve host address: ...</code>. Either way, the problem is that your container does not have a valid DNS setup. We have two recommended ways of addressing this.</p> <p>The first solution is to use the <code>dns</code> option offered by Docker. This is available in Docker run as well as Docker Compose. You can add <code>--dns 8.8.8.8 --dns 8.8.4.4</code> to use Google DNS servers. Or add the corresponding block in docker-compose.yml:</p> <pre><code>  dns:\n    - 8.8.8.8\n    - 8.8.4.4\n</code></pre> <p>You can of course use any DNS servers you want here. Google servers are popular. So is Cloudflare DNS.</p> <p>The second approach is to use some environment variables to override <code>/etc/resolv.conf</code> in the container. Using the same DNS servers as in the previous approach you can set:</p> <pre><code>OVERRIDE_DNS_1=8.8.8.8\nOVERRIDE_DNS_2=8.8.4.4\n</code></pre> <p>This will be read by the startup script and it will override the contents of <code>/etc/resolv.conf</code> accordingly. You can have one or more of these servers and they will be sorted alphabetically.</p> <p>What is the difference between these solutions?</p> <p>A good question as they both seem to override what DNS servers the container should use. However, they are not equal.</p> <p>The first solution uses the dns flags from Docker. This will mean that we instruct Docker to use these DNS servers for the container, but the resolv.conf file in the container will still point to the Docker DNS service. Docker might have many reasons for this but one of them is at least for service discovery. If you're running your container as a part of a larger docker-compose file or custom docker network and you want to be able to lookup the other containers based on their service names then you need to use the Docker DNS service. By using the <code>--dns</code> flags you should have both control of what DNS servers are used for external requests as well as container DNS lookup.</p> <p>The second solution is more direct. It rewrites the resolv.conf file so that it no longer refers to the Docker DNS service. The effect of this is that you lose Docker service discovery from the container (other containers in the same network can still resolve it) but you have cut out a middleman and potential point of error. I'm not sure why this sometimes is necessary but it has proven to fix the issue in some cases.</p> <p>A possible third option</p> <p>If you're facing the OpenVPN error (not curl) then your provider might have config files with IP addresses instead of DNS. That way your container won't need DNS to do a lookup for the server. Note that the trackers will still need DNS, so this will only solve the problem for you if it is your local network that in some way is blocking the DNS.</p>"},{"location":"faq/#container_loses_connection_after_some_time","title":"Container loses connection after some time","text":"<p>For some users, on some platforms, this is an issue. I have not encountered this myself - but there is no doubt that it's recurring. Why does the container lose connectivity? That we don't know and it could be many different reasons that manifest the same symptoms. We do however have some possible solutions.</p>"},{"location":"faq/#set_the_ping-exit_option_for_openvpn_and_restart-flag_in_docker","title":"Set the ping-exit option for OpenVPN and restart-flag in Docker","text":"<p>Most provider configs have a ping-restart option set. So if the tunnel fails, OpenVPN will restart and re-connect. That works well on regular systems. The problem is that if the container has lost internet connection restarting OpenVPN will not fix anything. What you can do though is to set/override this option using <code>OPENVPN_OPTS=--inactive 3600 --ping 10 --ping-exit 60</code>. This will tell OpenVPN to exit when it cannot ping the server for 1 minute.</p> <p>When OpenVPN exits, the container will exit. And if you've then set <code>restart=always</code> or <code>restart=unless-stopped</code> in your Docker config then Docker will restart the container and that could/should restore connectivity. VPN providers sometimes push options to their clients after they connect. This is visible in the logs if they do. If they push ping-restart that can override your settings. So you could consider adding <code>--pull-filter ignore ping</code> to the options above.</p> <p>This approach will probably work, especially if you're seeing logs like these from before:</p> <pre><code>Inactivity timeout (--ping-restart), restarting\nSIGUSR1[soft,ping-restart] received, process restarting\n</code></pre>"},{"location":"faq/#use_a_third-party_tool_to_monitor_and_restart_the_container","title":"Use a third-party tool to monitor and restart the container","text":"<p>The container has a health check script that is run periodically. It will report the health status to Docker and the container will show as \"unhealthy\" if basic network connectivity is broken. You can write your own script and add it to cron, or you can use a tool like https://github.com/willfarrell/docker-autoheal to look for and restart unhealthy containers.</p> <p>This container has the <code>autoheal</code> label by default so it is compatible with the willfarrell/autoheal image</p>"},{"location":"faq/#send_username_and_password_via_a_file","title":"Send Username and Password via a file","text":"<p>Depending on your setup, you may not want to send your VPN user/pass via environment variables (the main reason being, it is accessible via docker inspect). If you prefer, there are two methods of avoiding credentials to be set via environment variables:  - Option 1: Configure the container to use a file.   - Option 2: Configure the container to use a <code>secret</code>. (Only available for Docker Swarm)</p> <p>Procedure for Option 1: Configuring the container to use a file 1. Create a text file with a username and password in it, each on a separate line. For this example, we will assume it is located at <code>./openvpn-credentials.txt</code></p> <pre><code>this_is_my_username\nthis_is_my_password\n</code></pre> <ol> <li> <p>Set the Environment Variable for username/password to exactly: <code>**None**</code></p> </li> <li> <p>Mount the file in this exact path: <code>/config/openvpn-credentials.txt</code></p> </li> </ol> <p>Config example:</p> <pre><code>$ docker run --cap-add=NET_ADMIN -d \\\n              -v /your/storage/path/:/data \\\n              -v ./openvpn-credentials.txt:/config/openvpn-credentials.txt \\\n              -e OPENVPN_PROVIDER=PIA \\\n              -e OPENVPN_CONFIG=france \\\n              -e OPENVPN_USERNAME=**None** \\\n              -e OPENVPN_PASSWORD=**None** \\\n              -e LOCAL_NETWORK=192.168.0.0/16 \\\n              --log-driver json-file \\\n              --log-opt max-size=10m \\\n              -p 9091:9091 \\\n              haugene/transmission-openvpn\n</code></pre> <p>The example docker-compose.yml looks like this:</p> <pre><code>version: '3.3'\nservices:\n    transmission-openvpn:\n        cap_add:\n            - NET_ADMIN\n        volumes:\n            - '/your/storage/path/:/data'\n            - './openvpn-credentials.txt:/config/openvpn-credentials.txt'\n        environment:\n            - OPENVPN_PROVIDER=PIA\n            - OPENVPN_CONFIG=france\n            - OPENVPN_USERNAME=**None**\n            - OPENVPN_PASSWORD=**None**\n            - LOCAL_NETWORK=192.168.0.0/16\n        logging:\n            driver: json-file\n            options:\n                max-size: 10m\n        ports:\n            - '9091:9091'\n        image: haugene/transmission-openvpn\n</code></pre> <p>Procedure for Option 2: Configure the container to use a <code>secret</code></p> <p>Note: Docker Secrets are only available for Docker Swarm (<code>docker-compose</code>). If you run the container standalone, refer to Option 1.</p> <ol> <li>Create a text file with a username and password in it, each on a separate line. For this example, we will assume it is located at <code>./openvpn-credentials.txt</code></li> </ol> <pre><code>this_is_my_username\nthis_is_my_password\n</code></pre> <ol> <li>Mount the file as a secret like below. *The name of the secret must be exactly <code>openvpn_creds</code>, which will be exposed to the container at <code>/run/secrets/openvpn_creds</code>.</li> </ol> <p>The example docker-compose.yml looks like this:</p> <pre><code>version: '3.3'\nsecrets:\n  openvpn_creds:\n    file: './openvpn-credentials.txt'\nservices:\n    transmission-openvpn:\n        cap_add:\n            - NET_ADMIN\n        volumes:\n            - '/your/storage/path/:/data'\n        environment:\n            - OPENVPN_PROVIDER=PIA\n            - OPENVPN_CONFIG=france\n            - OPENVPN_USERNAME=**None**\n            - OPENVPN_PASSWORD=**None**\n            - LOCAL_NETWORK=192.168.0.0/16\n        logging:\n            driver: json-file\n            options:\n                max-size: 10m\n        secrets:\n            - openvpn_creds\n        ports:\n            - '9091:9091'\n        image: haugene/transmission-openvpn\n</code></pre> <p>Bonus tip: The same steps can be followed for <code>rpc_creds</code>, as shown in [How do I enable authentication in the web ui].</p>"},{"location":"faq/#auth_received_control_message_auth_failed","title":"AUTH: Received control message: AUTH_FAILED","text":"<p>If your logs end like this, the wrong username/password was sent to your VPN provider.</p> <pre><code>AUTH: Received control message: AUTH_FAILED\nSIGTERM[soft,auth-failure] received, process exiting\n</code></pre> <p>We can divide the possible errors here into three. You have entered the wrong credentials, the server has some kind of error or the container has messed up your credentials. We have had challenges with special characters. Having \"?= as part of your password has tripped up our scripts from time to time.</p> <p>NOTE Some providers have multiple sets of credentials. Some for OpenVPN, others for web login, proxy solutions, etc. Make sure that you use the ones intended for OpenVPN. PIA users: this has recently changed. It used to be a separate pair, but now you should use the same login as you do in the web control panel. Before you were supposed to use a username like x12345, now it's the p12345 one. There is also a 99 character limit on password length.</p> <p>First, check that your credentials are correct. Some providers have separate credentials for OpenVPN so it might not be the same as for their apps. Secondly, test a few different servers just to make sure that it's not just a faulty server. If this doesn't resolve it, it's probably the container.</p> <p>To verify this you can mount a volume to <code>/config</code> in the container. So for example <code>/temporary/folder:/config</code>. Your credentials will be written to <code>/config/openvpn-credentials.txt</code> when the container starts, more on that here. So by mounting this folder you will be able to check the contents of that text file. The first line should be your username, the second should be your password.</p> <p>This file is what's passed to OpenVPN. If your username/password is correct here then you should probably contact your provider.</p>"},{"location":"provider-specific/","title":"Provider specific settings","text":""},{"location":"provider-specific/#coming_soon","title":"COMING SOON","text":"<p>NOTE: This page is just moved from it's previous location. A re-write is coming. I'm on it (#1558)</p>"},{"location":"provider-specific/#nordvpn","title":"NORDVPN","text":"<p>The update script is based on the NordVPN API. The API sends back the best recommended OpenVPN configuration file based on the filters given.</p> <p>You have to use your service credentials instead of your regular email and password. They can be found here.</p> <p>Available ENV variables in the container to define via the NordVPN API the file to use are:</p> Variable Function Example <code>NORDVPN_COUNTRY</code> Two character country code. See /servers/countries for full list. <code>NORDVPN_COUNTRY=US</code> <code>NORDVPN_CATEGORY</code> Server type (P2P, Standard, etc). See /servers/groups for full list. Use either <code>title</code> or <code>identifier</code> from the list. <code>NORDVPN_CATEGORY=legacy_p2p</code> <code>NORDVPN_PROTOCOL</code> Either <code>tcp</code> or <code>udp</code>. (values identifier more available at https://api.nordvpn.com/v1/technologies, may need script adaptation) <code>NORDVPN_PROTOCOL=tcp</code> <code>NORDVPN_SERVER</code> Set VPN server FQDN to use, bypasses API recommendations and downloads server's config file. NORDVPN_SERVER= sg460.nordvpn.com <p>The file is then downloaded using the API to find the best server according to the variables, here an albanian, using tcp:</p> <ul> <li>selecting server (limit answer to 1): [ANSWER]= https://api.nordvpn.com/v1/servers/recommendations?filters[country_id]=2&amp;filters[servers_technologies][identifier]=openvpn_tcp&amp;filters[servers_group][identifier]=legacy_group_category&amp;limit=1</li> <li>download selected server's config: https://downloads.nordcdn.com/configs/files/ovpn_[NORDVPN_PROTOCOL]/servers/[ANSWER.0.HOSTNAME][] =&gt; https://downloads.nordcdn.com/configs/files/ovpn_tcp/servers/al9.nordvpn.com.tcp.ovpn</li> </ul> <p>One optional ENV var NORDVPN_TESTS can take value from 1 to 4. Expected generic results are written to logs.</p> NORDVPN_TESTS Comment 1 Test when nothing is set: All NORDVPN_{COUNTRY, PROTOCOL, CATEGORY} are not set 2 Test when category is not set: NORDVPN_{COUNTRY, PROTOCOL} are set, NORDVPN_CATEGORY is not set 3 Test when api returns no result, send a warning with current parameters. 4 Test when NORDVPN_SERVER is set, config file should be downloaded. <p>get list of servers and load: <code>curl --silent https://api.nordvpn.com/server/stats | jq '. | to_entries|sort_by(.value.percent) | \"\\(.[].key): \\(.[].value.percent)\"'</code></p> <p>get load of a specific server: <code>curl --silent https://api.nordvpn.com/server/stats/ca1509.nordvpn.com | jq '.percent'</code></p> <p>get list of available servers: <code>curl --silent https://api.nordvpn.com/server/stats | jq '. |to_entries | .[].key')</code></p>"},{"location":"provider-specific/#ovpn","title":"OVPN","text":"<p>The selection script parses the file names of the available on the official contrib repo (https://github.com/haugene/vpn-configs-contrib/tree/main/openvpn/ovpn).</p> <p>OVPN utilizes ENV variables:</p> Variable Function Example <code>OVPN_PROTOCOL</code> Specifies either TCP or UDP selection <code>OVPN_PROTOCOL=udp</code> <code>OVPN_COUNTRY</code> Specifies the country to connect to. <code>OVPN_COUNTRY=us</code> <code>OVPN_CITY</code> Specifies the city to connect to. <code>OVPN_CITY=chicago</code> <code>OVPN_CONNECTION</code> Uses either standard or multihop VPN connections.  Currntly, OVPN only supports UDP. <code>OVPN_CONNECTION=multihop</code> <p>As of August 29, 2022, the following options are available: | Type          | Options                                                                                                                                                            | Example                       | | ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------- | | <code>multihop</code>  | toronto (ca), zurich (ch), chicago (us), new-york (us), any-city (se)         | <code>OVPN_COUNTRY=ca   OVPN_CITY=toronto</code>          | | <code>standard</code> | vienna (at), sydney (au), toronto (ca) , zurich (ch), erfurt (de), frankfurt (de), offenbach (de), copenhagen (dk), madrid (es), helsinki (fl), paris (fr), london (gb), milan (it), tokyo (jp), oslo (no), warsaw (pl), bucharest (ro), gothenburg (se), malmo (se), stockholm (se), sundsvall (se), singapore (sg), kyiv (ua), atlanta (us), los-angeles (us), miami (us), new-york (us), any-city (de), any-city (se), any-city (us) | <code>OVPN_COUNTRY=us   OVPN_CITY=new-york</code> |</p> <p>Review https://github.com/haugene/vpn-configs-contrib/tree/main/openvpn/ovpn for updates to country and city options.  </p>"},{"location":"provider-specific/#mullvad_ovpn","title":"MULLVAD &amp; OVPN","text":"<p>According to (#1355) ipv6 needs to be enabled for mullvad vpn this is an example for docker compose</p> <pre><code># ipv6 must be enabled for Mullvad to work\n        sysctls:\n            - \"net.ipv6.conf.all.disable_ipv6=0\"\n</code></pre> <p>or add following line to docker run</p> <pre><code>--sysctl net.ipv6.conf.all.disable_ipv6=0\n</code></pre> <p>The same is true for provider OVPN.</p>"},{"location":"provider-specific/#njalla","title":"NJAL.LA","text":"<p>Njal.la provides <code>.ovpn</code> configuration file. User needs to specify to enable ipv6.</p> <p>Here is a full example of <code>docker-compose.yml</code> file, assuming configuration file named <code>Njalla-VPN.ovpn</code> is under local <code>config</code> subdirectory.</p> <pre><code>version: '3.3'\nservices:\n    transmission-openvpn:\n      cap_add:\n        - NET_ADMIN\n      volumes:\n        - ./config/Njalla-VPN.ovpn:/etc/openvpn/custom/default.ovpn:rw\n        - ./data:/data:rw\n      dns:\n        - 1.1.1.1\n      devices:\n        - /dev/net/tun\n      sysctls:\n        # must enable ipv6 to have njal.la work\n        - net.ipv6.conf.all.disable_ipv6=0\n      environment:\n        - OPENVPN_PROVIDER=CUSTOM\n        - OPENVPN_USERNAME=user\n        - OPENVPN_PASSWORD=pass\n        - LOCAL_NETWORK=192.168.1.0/24\n        - HEALTH_CHECK_HOST=google.com\n      ports:\n         - '9091:9091'\n      logging:\n        driver: json-file\n        options:\n          max-size: 10m\n      image: haugene/transmission-openvpn:latest\n</code></pre>"},{"location":"provider-specific/#protonvpn","title":"PROTONVPN","text":"<p>PROTONVPN provides <code>.ovpn</code> configuration files. Just download the one you want to connect with and which allows P2P.</p>"},{"location":"provider-specific/#prerequisites","title":"Prerequisites:","text":"<p>User needs to have a paid account.</p> <ol> <li>download your ProtonVPN ovpn file from a destination which allows P2P.</li> <li>in the directory with your docker-compose file, create a directory: <code>mkdir protonvpn</code></li> <li>copy your ovpn file (node-.protonvpn.udp.ovpn) from step 1 to the protonvpn directory <li>add the environment vars below and add +pmp to your username if you want to use port forwarding.</li> <li>add the update-port.sh script for ProtonVPN from vpn-configs-contrib to the protonvpn directory of step 2.</li> <p>Here is a full example of <code>docker-compose.yml</code> file, assuming configuration file named <code>node-&lt;country of choice&gt;.protonvpn.udp</code> is under local <code>protonvpn</code> subdirectory.</p> <pre><code>version: 3.7.1\nservices:\n    transmission-openvpn:\n        container_name: TransmissionVPN\n        restart: on-failure:2\n        cap_add:\n            - NET_ADMIN\n        volumes:\n            - ./protonvpn/:/etc/openvpn/custom/\n            - /your/config/path/:/config # where transmission-home is stored\n            - /your/storage/path/:/data # where transmission will store the data\n        environment:\n            - OPENVPN_PROVIDER=custom\n            - OPENVPN_CONFIG=node-&lt;country of choice&gt;.protonvpn.udp\n            - OPENVPN_USERNAME=&lt;username&gt;+pmp\n            - OPENVPN_PASSWORD=&lt;password&gt;\n            - LOCAL_NETWORK=192.168.0.0/16\n        logging:\n            driver: json-file\n            options:\n                max-size: 10m\n        ports:\n            - 9091:9091\n        image: haugene/transmission-openvpn\n\n</code></pre> <p>After starting your container, the <code>peer listening port</code> in Transmission should be open after a minute or so. </p> <p>If not you can jump in the container and run the script manually and see which error you get, or set the debug env variable: <code>- DEBUG=true</code> and look in the logging of your container for the output of the script <code>update-port.sh</code></p> <p>To check which IP address your VPN is currently connected to, run this script:</p> <pre><code>#!/bin/bash\n\nf_container_name()\n{\ndocker ps --format \"{{.Names}}\"| grep -i transmission\n}\n\nf_find_all()\n{\ncurl --silent ipinfo.io/$ext_ip\n}\n\nvar_cont_name=$(f_container_name)\next_ip=$(docker exec $var_cont_name curl --silent \"http://ipinfo.io/ip\")\necho \"Transmission VPN currently connected to IP address: $ext_ip\"\necho \"This IP address is in the following country: \"\nf_find_all\n</code></pre>"},{"location":"rss-plugin/","title":"RSS plugin","text":"<p>The Transmission RSS plugin can optionally be run as a separate container. It allows downloading torrents based on an RSS URL, see Plugin page.</p> <pre><code>$ docker run -d \\\n      -e \"RSS_URL=&lt;URL&gt;\" \\\n      --link &lt;transmission-container&gt;:transmission \\\n      --name \"transmission-rss\" \\\n      haugene/transmission-rss\n</code></pre> <p>At first start a transmission-rss.conf file will be created in /etc if no manual one is mounted A manual transmission-rss.conf file can be mounted into the container to add additional parameters, e.g. login details to rpc example:</p> <pre><code>$ docker run -d \\\n      -v &lt;transmission-rss.conf&gt;:/etc/transmission-rss.conf \\\n      --link &lt;transmission-container&gt;:transmission \\\n      --name \"transmission-rss\" \\\n      haugene/transmission-rss\n</code></pre> <p>transmission-rss.conf example</p> <pre><code>feeds:\n  - url: &lt;placeholder&gt;\n    download_path: &lt;placeholder&gt;\n    regexp: &lt;placeholder&gt;\n\nserver:\n  host: transmission\n  port: 9091\n  rpc_path: /transmission/rpc\n\nlogin:\n  username: &lt;username&gt;\n  password: &lt;password&gt;\n\n</code></pre>"},{"location":"run-container/","title":"Running the container","text":"<p>Many platforms ship with a Docker runtime and have their own way of setting this up. I'm then thinking about NAS servers specifically, but also Unraid and others. In addition to this, we have container management solutions like Portainer</p> <p>This page will only discuss the tooling that a Docker installation comes with. That means <code>docker run ..</code> and <code>docker-compose</code>. In the end, that is what the other managers do as well and it's the common ground here. I'm very happy to set up a platform-specific installation page and link to it from here. Open an issue or PR if you want to contribute with documentation for your favourite platform.</p> <p>The images available on the Docker Hub are multi-arch manifests. This means that they point to multiple images that are built for different CPU architectures like ARM for Raspberry Pi. You can <code>haugene/transmission-openvpn</code> on any of these architectures and Docker will get the correct one.</p>"},{"location":"run-container/#starting_the_container","title":"Starting the container","text":"<p>The example Docker run command looks like this:</p> <pre><code>$ docker run --cap-add=NET_ADMIN -d \\\n              -v /your/storage/path/:/data \\\n              -v /your/config/path/:/config \\\n              -e OPENVPN_PROVIDER=PIA \\\n              -e OPENVPN_CONFIG=france \\\n              -e OPENVPN_USERNAME=user \\\n              -e OPENVPN_PASSWORD=pass \\\n              -e LOCAL_NETWORK=192.168.0.0/16 \\\n              --log-driver json-file \\\n              --log-opt max-size=10m \\\n              -p 9091:9091 \\\n              haugene/transmission-openvpn\n</code></pre> <p>The example docker-compose.yml looks like this:</p> <pre><code>version: '3.3'\nservices:\n    transmission-openvpn:\n        cap_add:\n            - NET_ADMIN\n        volumes:\n            - '/your/storage/path/:/data'\n            - '/your/config/path/:/config'\n        environment:\n            - OPENVPN_PROVIDER=PIA\n            - OPENVPN_CONFIG=france\n            - OPENVPN_USERNAME=user\n            - OPENVPN_PASSWORD=pass\n            - LOCAL_NETWORK=192.168.0.0/16\n        logging:\n            driver: json-file\n            options:\n                max-size: 10m\n        ports:\n            - '9091:9091'\n        image: haugene/transmission-openvpn\n</code></pre> <p>These configs are equivalent. Running <code>docker-compose up</code> with that compose file will result in the same options being sent to the Docker engine as the run statement before it.</p>"},{"location":"run-container/#three_things_to_remember","title":"Three things to remember","text":""},{"location":"run-container/#1_the_container_assumes_that_you_mount_a_folder_to_data","title":"1. The container assumes that you mount a folder to /data","text":"<p>Technically you don't have to do this, but it is by far the most manageable way of getting the downloaded files onto your host system and Transmission will store its state there. So if you don't mount this directory then you will lose all your torrents on image updates.</p>"},{"location":"run-container/#2_it_is_not_mandatory_but_setting_openvpn_config_is_good","title":"2. It is not mandatory, but setting OPENVPN_CONFIG is good","text":"<p>If you don't set this then there should be a default config for each provider that is chosen, and that should work fine. The benefit of choosing yourself is that you can choose a region that is closer to you and that might be better for speed. I also believe that tinkering with this builds some familiarity with the image and some confidence and understanding for future debugging.</p> <p>We're now moving towards a setup where we download the configs for our providers when the container starts. That is great from a maintenance perspective, but it also means that we don't know the valid choices for the providers ahead of time. A tip for finding out is to set <code>OPENVPN_CONFIG=dummy</code> and start it. This will fail, but in the logs, it will print all the valid options.</p> <p>Pro tip: choose multiple servers. For example: <code>OPENVPN_CONFIG=france,sweden,austria,italy,belgium</code> This will ensure a location near you, but at the same time, it will allow some redundancy. Set Docker to restart the container automatically and you have a failover mechanism. The container chooses one of the configs at random when it starts and it will bounce from server to server until it finds one that works.</p>"},{"location":"run-container/#3_you_might_not_be_able_to_access_the_web_ui_on_the_first_try","title":"3. You might not be able to access the Web UI on the first try","text":"<p>The <code>LOCAL_NETWORK=192.168.0.0/16</code> tries to fix this for you, but it might not work if your local LAN DHCP server hands out addresses outside that range.</p> <p>If your local network is in the <code>10.x.y.z</code> space for example then you need to set <code>LOCAL_NETWORK=10.x.0.0/16</code> or <code>LOCAL_NETWORK=10.x.y.0/24</code>. These are called CIDR addresses and you can read up on them. The short story is that /24 will allow for any value in the last digit place while /16 will allow any value in the two last places. Be sure to only allow IPs that are in the private IP ranges. This option punches a hole in the VPN for the IPs that you specify. It is necessary to reach your Web UI but narrower ranges are better than wide ones.</p> <p>With that said. If you know that you're on a \"typical\" network with your router at 192.168.1.1, then <code>LOCAL_NETWORK=192.168.1.0/24</code> is better than <code>LOCAL_NETWORK=192.168.0.0/16</code>. That way you only allow access from 192.168.1.x instead of 192.168.x.y.</p> <p>There is an alternative to the LOCAL_NETWORK environment variable, and that is a reverse proxy in the same docker network as the VPN container. Because this topic is both quite complex and very important there is a separate page on VPN and Networking in the container and it goes into depth on why this is.</p>"},{"location":"supported-providers/","title":"Supported providers","text":""},{"location":"supported-providers/#how_we_manage_vpn_providers","title":"How we manage VPN providers","text":"<p>The container used to come bundled with a bunch of config files for a range of VPN providers. This was fine when it was a handful or even a dozen supported providers, but as we approached 50 providers and 10k configs there wasn't time for anything else than keeping them up to date.</p> <p>So we've tried to come up with a more maintainable setup.  We have split the .ovpn configs out to a separate repository at: https://github.com/haugene/vpn-configs-contrib.</p> <p>All static configs that have to be manually updated will live there and be pulled on container startup. We will try to set up a CODEOWNERS scheme and ask for more help from the community to keep them up to date.</p> <p>Some providers are still provided from the core project and those are the ones that have implemented a script for fetching the configs dynamically. Going forward we will allow code in this project, not config.</p> <p>So that is the story of how we now have two types of providers: <code>internal</code> and <code>external</code>. The benefit of having native support for external configs is that it is much simpler for a user to make a fork of the config repo and simply tell the container to use his or her fork. This way we can hopefully empower many more to help out with keeping our providers up to date and adding new ones.</p>"},{"location":"supported-providers/#out-of-the-box_supported_providers","title":"Out-of-the-box supported providers","text":"<p>If you can't find your provider you are welcome to head over to the  config repo to request it or add it yourself. Keep in mind that some providers generate configs per user where the authentication details are a part of the config and they can therefore not be added here but has to be manually supplied by the user. You can use any OpenVPN config with this container by mounting it as a file in the container. For more info on that see the using a custom provider section.</p>"},{"location":"supported-providers/#internal_providers","title":"Internal Providers","text":"<p>These providers are implemented as a script in this project and will automatically download new configs directly from the provider on container startup.</p> Provider Name Config Value (<code>OPENVPN_PROVIDER</code>) IPVanish <code>IPVANISH</code> NordVPN <code>NORDVPN</code> Private Internet Access <code>PIA</code> VyprVpn <code>VYPRVPN</code>"},{"location":"supported-providers/#external_providers","title":"External Providers","text":"<p>These providers are fetched from our config repo on startup. They have to be manually updated in that repo when the provider changes them but we're trying to keep them up to date.</p> <p>Note that we try to keep this list in sync but it is the files and folders in the config repo that ultimately is the most up-to-date list of configs and providers that are supported.</p> Provider Name Config Value (<code>OPENVPN_PROVIDER</code>) Anonine <code>ANONINE</code> AnonVPN <code>ANONVPN</code> BlackVPN <code>BLACKVPN</code> BTGuard <code>BTGUARD</code> Cryptostorm <code>CRYPTOSTORM</code> ExpressVPN <code>EXPRESSVPN</code> FastestVPN <code>FASTESTVPN</code> FreeVPN <code>FREEVPN</code> FrootVPN <code>FROOT</code> FrostVPN <code>FROSTVPN</code> Getflix <code>GETFLIX</code> GhostPath <code>GHOSTPATH</code> Giganews <code>GIGANEWS</code> HideMe <code>HIDEME</code> HideMyAss <code>HIDEMYASS</code> IntegrityVPN <code>INTEGRITYVPN</code> IronSocket <code>IRONSOCKET</code> Ivacy <code>IVACY</code> IVPN <code>IVPN</code> Mullvad <code>MULLVAD</code> OctaneVPN <code>OCTANEVPN</code> OVPN <code>OVPN</code> Privado <code>PRIVADO</code> PrivateVPN <code>PRIVATEVPN</code> ProtonVPN <code>PROTONVPN</code> proXPN <code>PROXPN</code> PureVPN <code>PUREVPN</code> RA4W VPN <code>RA4W</code> SaferVPN <code>SAFERVPN</code> SlickVPN <code>SLICKVPN</code> SlickVPNCore <code>SLICKVPNCORE</code> Smart DNS Proxy <code>SMARTDNSPROXY</code> SmartVPN <code>SMARTVPN</code> Surfshark <code>SURFSHARK</code> TigerVPN <code>TIGER</code> TorGuard <code>TORGUARD</code> Trust.Zone <code>TRUSTZONE</code> TunnelBear <code>TUNNELBEAR</code> VPN.AC <code>VPNAC</code> VPNArea.com <code>VPNAREA</code> VPNBook.com <code>VPNBOOK</code> VPNFacile <code>VPNFACILE</code> VPN.ht <code>VPNHT</code> VPNTunnel <code>VPNTUNNEL</code> VPNUnlimited <code>VPNUNLIMITED</code> Windscribe <code>WINDSCRIBE</code> ZoogVPN <code>ZOOGVPN</code>"},{"location":"supported-providers/#use_your_own_config_without_building_the_image","title":"Use your own config without building the image","text":"<p>If you have a .ovpn file from your VPN provider and you want to use it but you either don't know how to build the image yourself or if you don't want to there is another way.</p> <p>Check out the guide for this in the config repo.</p>"},{"location":"supported-providers/#using_a_local_single_ovpn_file_from_a_provider","title":"Using a local single .ovpn file from a provider","text":"<p>For some providers, like AirVPN, the .ovpn files are generated per user and contain credentials.  These files can not be hosted anywhere publicly visible. Then you can mount the files into the container and use them directly from your local host.</p> <p>Grab all files from your provider (usually a .zip file to download &amp; unzip)</p> <p>Copy them into a folder on your Docker host, there might be .ovpn files and ca.cert as well (example below /volume1/docker/ipvanish/)</p> <p>Mount the volume Compose sample:</p> <pre><code>             - /volume1/docker/ipvanish/:/etc/openvpn/custom/\n</code></pre> <p>Declare the Custom provider, the target server and login/password Also important to note here is that <code>OPENVPN_CONFIG</code> value needs to be the name of the ovpn file wanting to be referenced in the <code>/etc/openvpn/custom</code> volume. In the example below the ovpn file name is <code>ipvanish-UK-Maidenhead-lhr-c02.ovpn</code> </p> <p>Compose sample:</p> <pre><code>            - OPENVPN_PROVIDER=custom\n            - OPENVPN_CONFIG=ipvanish-UK-Maidenhead-lhr-c02\n            - OPENVPN_USERNAME=user\n            - OPENVPN_PASSWORD=pass\n</code></pre> <p>Docker ENV vars sample: </p> <pre><code>              -e OPENVPN_PROVIDER=custom \\\n              -e OPENVPN_CONFIG=ipvanish-UK-Maidenhead-lhr-c02 \\\n              -e OPENVPN_USERNAME=user \\\n              -e OPENVPN_PASSWORD=pass \\\n</code></pre>"},{"location":"supported-providers/#do_not_mount_single_config_file","title":"Do not mount single config file","text":"<p>Do not mount a single config directly. The container will fail if you try, since it causes sed errors when modify-openvpn-config.sh is executed. Instead mount the directory where the config exists.</p> <pre><code>sed: cannot rename /etc/openvpn/custom/sedHeF3gS: Device or resource busy\n</code></pre>"},{"location":"tips-tricks/","title":"Use Google DNS servers","text":"<p>Some have encountered problems with DNS resolving inside the docker container. This causes trouble because OpenVPN will not be able to resolve the host to connect to. If you have this problem use Docker's --dns flag and try using Google's DNS servers by adding --dns 8.8.8.8 --dns 8.8.4.4 as parameters to the usual run command.</p>"},{"location":"tips-tricks/#restart_the_container_if_the_connection_is_lost","title":"Restart the container if the connection is lost","text":"<p>If the VPN connection fails or the container for any other reason loses connectivity, you want it to recover from it. One way of doing this is to set the environment variable <code>OPENVPN_OPTS=--inactive 3600 --ping 10 --ping-exit 60</code> and use the --restart=always flag when starting the container. This way OpenVPN will exit if ping fails over a period of time which will stop the container and then the Docker daemon will restart it.</p>"},{"location":"tips-tricks/#let_other_containers_use_the_vpn","title":"Let other containers use the VPN","text":"<p>To let other containers use VPN you have to add them to the same Service network as your VPN container runs, you can do this by adding <code>network_mode: \"service:transmission-openvpn\"</code>. Additionally, you have to set <code>depends_on</code> to the <code>transmission-openvpn</code> service to let docker-compose know that your new container should start after <code>transmission-openvpn</code> is up and running. As the final step, you can add <code>healthcheck</code> to your service.</p>"},{"location":"tips-tricks/#example_jackett","title":"Example (Jackett):","text":"<p>As an example, let's add Jackett to the <code>transmission-openvpn</code> network based on the example from Running the container:</p> <pre><code>version: '3.3'\nservices:\n    transmission-openvpn:\n        cap_add:\n            - NET_ADMIN\n        volumes:\n            - '/your/storage/path/:/data'\n        environment:\n            - OPENVPN_PROVIDER=PIA\n            - OPENVPN_CONFIG=france\n            - OPENVPN_USERNAME=user\n            - OPENVPN_PASSWORD=pass\n            - LOCAL_NETWORK=192.168.0.0/16\n        logging:\n            driver: json-file\n            options:\n                max-size: 10m\n        ports:\n            - '9091:9091'\n            - '9117:9117'  # This is Jackett Port \u2013 managed by VPN Service Network\n        image: haugene/transmission-openvpn\n    jackett:\n        image: lscr.io/linuxserver/jackett:latest\n        container_name: jackett\n        environment:\n            - PUID=1000\n            - PGID=1000\n            - TZ=Europe/London\n            - AUTO_UPDATE=true #optional\n            - RUN_OPTS=&lt;run options here&gt; #optional\n        volumes:\n            - &lt;path to data&gt;:/config\n            - &lt;path to blackhole&gt;:/downloads\n        # You have to comment ports, they should be managed in transmission-openvpn section now.\n#       ports:\n#           - 9117:9117\n        restart: unless-stopped\n        network_mode: \"service:transmission-openvpn\" # Add to the transmission-openvpn Container Network\n        depends_on:\n            - transmission-openvpn # Set dependency on transmission-openvpn Container\n        healthcheck: # Here you will check if transmission is reachable from the Jackett container via localhost\n            test: curl -f http://localhost:9091 || exit 1\n            # Use this test if you protect your transmission with a username and password \n            # comment the test above and un-comment the line below.\n            #test: curl -f http://${TRANSMISSION_RPC_USERNAME}:${TRANSMISSION_RPC_PASSWORD}@localhost:9091 || exit 1\n            interval: 5m00s\n            timeout: 10s\n            retries: 2\n</code></pre>"},{"location":"tips-tricks/#check_if_the_container_is_using_vpn","title":"Check if the container is using VPN","text":"<p>After the container starts, simply call <code>curl</code> under it to check your IP address, for example with Jackett you should see your VPN IP address as output:</p> <pre><code>docker exec jackett curl -s https://api.ipify.org\n</code></pre> <p>You can also check that Jackett is attached to the VPN network by pinging it from the <code>transmission-openvpn</code> Container <code>localhost</code>:</p> <pre><code>docker exec transmission-vpn curl -Is http://localhost:9117\nHTTP/1.1 301 Moved Permanently\nDate: Tue, 17 May 2022 19:58:19 GMT\nServer: Kestrel\nLocation: /UI/Dashboard\n</code></pre>"},{"location":"tips-tricks/#example_dante","title":"Example (Dante):","text":"<p>As an example, let's add Dante socks5 proxy to the <code>transmission-openvpn</code> network based on the example from Running the container:</p> <pre><code>version: '3.3'\nservices:\n    transmission-openvpn:\n        cap_add:\n            - NET_ADMIN\n        volumes:\n            - '/your/storage/path/:/data'\n        environment:\n            - OPENVPN_PROVIDER=PIA\n            - OPENVPN_CONFIG=france\n            - OPENVPN_USERNAME=user\n            - OPENVPN_PASSWORD=pass\n            - LOCAL_NETWORK=192.168.0.0/16\n        logging:\n            driver: json-file\n            options:\n                max-size: 10m\n        ports:\n            - '9091:9091'\n            - '1080:1080'  # This is Dante Socks5 Port \u2013 managed by VPN Service Network\n        restart: unless-stopped\n        image: haugene/transmission-openvpn\n\n    socks5-proxy:\n        image: wernight/dante\n        restart: unless-stopped\n        network_mode: service:transmission-openvpn\n        depends_on:\n            - transmission-openvpn\n        command:\n            - /bin/sh\n            - -c\n            - |\n                echo \"Waiting for VPN to connect . . .\"\n                while ! ip link show tun0 &gt;/dev/null 2&gt;&amp;1 || ! ip link show tun0 | grep -q \"UP\"; do sleep 1; done\n                echo \"VPN connected. Starting proxy service . . .\"\n                sed -i 's/^\\(external:\\).*/\\1 tun0/' /etc/sockd.conf\n                sockd\n</code></pre>"},{"location":"tips-tricks/#test_dante_socks5_proxy","title":"Test Dante socks5 proxy","text":"<pre><code>curl -x socks5h://{docker-host-ip}:1080 http://ip.ip-check.net\n</code></pre>"},{"location":"tips-tricks/#bonus_socks5_tip","title":"Bonus socks5 tip","text":"<p>With the Proxy SwitchyOmega Chrome/Edge extension, you can configure specific websites on your local machine to route through your socks5 proxy server.</p>"},{"location":"tips-tricks/#reach_sleep_or_hibernation_on_your_host_if_no_torrents_are_active","title":"Reach sleep or hibernation on your host if no torrents are active","text":"<p>By default, Transmission will always scrape trackers, even if all torrents have completed their activities, or they have been paused manually. This will cause Transmission to be always active, therefore never allow your host server to be inactive and go to sleep/hibernation/whatever. If this is something you want, you can add the following variable when creating the container. It will turn off a hidden setting in Transmission which will stop the application to scrape trackers for paused torrents. Transmission will become inactive, and your host will reach the desired state.</p> <pre><code>-e \"TRANSMISSION_SCRAPE_PAUSED_TORRENTS_ENABLED=false\"\n</code></pre>"},{"location":"tips-tricks/#running_it_on_a_nas","title":"Running it on a NAS","text":"<p>Several popular NAS platforms support Docker containers. You should be able to set up and configure this container using their web interfaces. As of version 3.0 of this image creates a TUN interface inside the container by default. This previously had to be mounted from the host which was an issue for some NAS servers. The assumption is that this should now be fixed. If you have issues and the logs seem to blame \"/dev/net/tun\" in some way then you might consider trying to mount a host device and see if that works better. Setting up a TUN device is probably easiest to accomplish by installing an OpenVPN package for the NAS. This should set up the device and you can mount it. There are some issues involved in running it on Synology NAS,  Please see this issue that discusses solutions</p>"},{"location":"tips-tricks/#systemd_integration","title":"Systemd Integration","text":"<p>On many modern Linux systems, including Ubuntu, systemd can be used to start the transmission-openvpn at boot time, and restart it after any failure.</p> <p>Save the following as <code>/etc/systemd/system/transmission-openvpn.service</code>, and replace the OpenVPN PROVIDER/USERNAME/PASSWORD directives with your settings, and add any other directives that you're using.</p> <p>This service is assuming that there is a <code>bittorrent</code> user set up with a home directory at <code>/home/bittorrent/</code>. The data directory will be mounted at <code>/home/bittorrent/data/</code>. This can be changed to whichever user and location you're using.</p> <p>OpenVPN is set to exit if there is a connection failure. OpenVPN exiting triggers the container to also exit, and then the <code>Restart=always</code> definition in the <code>transmission-openvpn.service</code> file tells systems to restart things again.</p> <pre><code>[Unit]\nDescription=haugene/transmission-openvpn docker container\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nUser=bittorrent\nTimeoutStartSec=0\nExecStartPre=-/usr/bin/docker kill transmission-openvpn\nExecStartPre=-/usr/bin/docker rm transmission-openvpn\nExecStartPre=/usr/bin/docker pull haugene/transmission-openvpn\nExecStart=/usr/bin/docker run \\\n        --name transmission-openvpn \\\n        --cap-add=NET_ADMIN \\\n        -v /home/bittorrent/data/:/data \\\n        -e \"OPENVPN_PROVIDER=TORGUARD\" \\\n        -e \"OPENVPN_USERNAME=bittorrent@example.com\" \\\n        -e \"OPENVPN_PASSWORD=hunter2\" \\\n        -e \"OPENVPN_CONFIG=CA Toronto\" \\\n        -e \"OPENVPN_OPTS=--inactive 3600 --ping 10 --ping-exit 60\" \\\n        -p 9091:9091 \\\n        --dns 8.8.8.8 \\\n        --dns 8.8.4.4 \\\n        haugene/transmission-openvpn\nRestart=always\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Then enable and start the new service with:</p> <pre><code>$ sudo systemctl enable /etc/systemd/system/transmission-openvpn.service\n$ sudo systemctl restart transmission-openvpn.service\n</code></pre> <p>If it is stopped or killed in any fashion, systemd will restart the container. If you do want to shut it down, then run the following command and it will stay down until you restart it.</p> <pre><code>$ sudo systemctl stop transmission-openvpn.service\n# Later ...\n$ sudo systemctl start transmission-openvpn.service\n</code></pre>"},{"location":"tips-tricks/#running_with_traefik_reverse_proxy","title":"Running with Traefik reverse proxy","text":"<p>A working example of running this container behind a traefik reverse proxy can be found here: Config</p>"},{"location":"tips-tricks/#running_this_container_with_podman","title":"Running this container with Podman","text":"<p>The <code>podman run</code> command is almost identical to the one mentioned in README.md but with the following exception:</p> <p>Instead <code>--cap-add=NET_ADMIN</code> you have to specify <code>--cap-add=NET_ADMIN,NET_RAW,MKNOD</code>. <code>MKNOD</code> and <code>NET_ADMIN</code> are necessary so Podman can create the tunnel, <code>NET_RAW</code> is needed for <code>ping</code>.</p>"},{"location":"v3/","title":"Version 3.0 released - we have some breaking changes (but not much)","text":"<p>Those of you who are following this project know that we have had some larger changes coming for a while. Hobby projects often get last in line for some love and care, and it took longer than I hoped but here we are.</p> <p>Some highlights on version 3.0:</p> <ul> <li>We're dropping the ubuntu based image and making alpine the default (reduce double maintenance)</li> <li>We're making Transmission settings persistent by default, removing the need for all the environment variables (but keeping support for it)</li> <li>We're making it easier to provide your own OpenVPN (.ovpn) config file - adding scripts in the container to modify provider configs as needed to fit the container setup. (still in early stages at this point)</li> <li>We're adding a standardized way to add scripts for doing the necessary setup of a provider. This usually means downloading a .ovpn config bundle, unpacking it and modifying it correctly to work in this container.</li> </ul> <p>Hopefully, these changes will improve the usability of this container. As maintainers, we also hope that it will free up time to keep the container up-to-date and stable instead of managing thousands of .ovpn files coming and going.</p> <p>I'll try to keep a list of breaking changes here, and add to it if we come across more:</p> <ul> <li>The CREATE_TUN_DEVICE variable now defaults to true. Mounting /dev/net/tun will lead to an error message in the logs unless you explicitly set it to false.</li> <li>The DOCKER_LOG variable is renamed to LOG_TO_STDOUT</li> <li>If Transmission is running but you can't connect to torrents, try deleting the settings.json file (or renaming it to .backup) and restarting.</li> </ul> <p>PS: Now more than ever. We appreciate that you report bugs and issues when you find them. But as there might be more than usual, please make sure you search and look for a similar one before possibly creating a duplicate. And you can always revert to the latest tag on the 2.x versions which is 2.14. Instead of running with <code>haugene/transmission-openvpn</code> simply use <code>haugene/transmission-openvpn:2.14</code> instead. We hope that won't be necessary though :)</p>"},{"location":"vpn-networking/","title":"VPN and Networking","text":""},{"location":"vpn-networking/#coming_soon","title":"COMING SOON","text":"<p>NOTE: This page is just moved from it's previous location. A re-write is coming and I know that there are links to this page that promises more than what's here now. I'm on it (#1558)</p>"},{"location":"vpn-networking/#access_the_webui","title":"Access the WebUI","text":"<p>But what's going on? My http://my-host:9091 isn't responding? This is because the VPN is active, and since docker is running in a different ip range than your client the response to your request will be treated as \"non-local\" traffic and therefore be routed out through the VPN interface.</p>"},{"location":"vpn-networking/#how_to_fix_this","title":"How to fix this","text":"<p>The container supports the <code>LOCAL_NETWORK</code> environment variable. For instance if your local network uses the IP range 192.168.0.0/24 you would pass <code>-e LOCAL_NETWORK=192.168.0.0/24</code>.</p> <p>Alternatively you can reverse proxy the traffic through another container, as that container would be in the docker range. There is a reverse proxy being built with the container. You can run it using the command below or have a look in the repository proxy folder for inspiration for your own custom proxy.</p> <pre><code>$ docker run -d \\\n      --link &lt;transmission-container&gt;:transmission \\\n      -p 8080:8080 \\\n      --name transmission-openvpn-proxy \\\n      haugene/transmission-openvpn-proxy\n</code></pre>"},{"location":"vpn-networking/#access_the_rpc","title":"Access the RPC","text":"<p>You need to add a / to the end of the URL to be able to connect. Example: http://my-host:9091/transmission/rpc/</p>"},{"location":"vpn-networking/#controlling_transmission_remotely","title":"Controlling Transmission remotely","text":"<p>The container exposes /config as a volume. This is the directory where the supplied transmission and OpenVPN credentials will be stored. If you have transmission authentication enabled and want scripts in another container to access and control the transmission-daemon, this can be a handy way to access the credentials. For example, another container may pause or restrict transmission speeds while the server is streaming video.</p>"},{"location":"web-proxy/","title":"Web Proxy","text":""},{"location":"web-proxy/#web_proxy_configuration_options","title":"Web proxy configuration options","text":"<p>This container also contains a web-proxy server to allow you to tunnel your web browser traffic through the same OpenVPN tunnel. The proxy used is Privoxy and is highly configurable using the built-in web interface available on config.privoxy.org (available once your browser is correctly configured to use the localhost:8118 HTTP Proxy). This is useful if you are using a private tracker that needs to see you log in from the same IP address you are torrenting from. The default listening port is 8118. Note that only ports above 1024 can be specified as all ports below 1024 are privileged and would otherwise require root permissions to run. Remember to add a port binding for your selected (or default) port when starting the container.</p> Variable Function Example <code>WEBPROXY_ENABLED</code> Enables the web proxy <code>WEBPROXY_ENABLED=true</code> <code>WEBPROXY_PORT</code> Sets the listening port <code>WEBPROXY_PORT=8118</code> <code>WEBPROXY_BIND_ADDRESS</code> Sets the listen address <code>WEBPROXY_BIND_ADDRESS=0.0.0.0</code> <p>The listening address is the one found bound to the eth0 interface unless <code>WEBPROXY_BIND_ADDRESS</code> is set.</p> <p><code>adr=$(ip -4  a show eth0| grep -oP \"(?&lt;=inet )([^/]+)\")</code></p>"}]}